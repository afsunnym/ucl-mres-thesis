{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30595437-88a5-407e-852b-11d4a3ae611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b829a5e-60f8-4a9a-a42d-9bcb862bb3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "\n",
    "output_dir = \"outputs\"\n",
    "\n",
    "csv_path = os.path.join(output_dir, \"OD_ADULTS_Timeindex_Motive_location_tripexpansionfactors.csv\")\n",
    "final_df = pd.read_csv(csv_path, header=[0,1], low_memory=False)\n",
    "\n",
    "gdf_path = os.path.join(output_dir, \"H3_res9/Municipios_2023_h3_res9.shp\")\n",
    "hex_gdf = gpd.read_file(gdf_path)\n",
    "if 'h3_index' in hex_gdf.columns:\n",
    "    hex_gdf = hex_gdf.rename(columns={'h3_index': 'hexagon'})\n",
    "hex_gdf['hexagon'] = hex_gdf['hexagon'].astype(str)\n",
    "\n",
    "\n",
    "hex_df = final_df.xs('hexagon', level=1, axis=1)\n",
    "motive_df = final_df.xs('motive', level=1, axis=1)\n",
    "expf_df = final_df.xs('tripexpfactor', level=1, axis=1)\n",
    "\n",
    "urbanised_gdf = gpd.read_file(\"ucl-mres-thesis/SPMA Urbanised Areas-MapBiomas/2022/AU_2022.shp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ca834d-8346-4832-bd59-08a6a7656edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRS alignment for all spatial joins/plots\n",
    "if hex_gdf.crs != urbanised_gdf.crs:\n",
    "    urbanised_gdf = urbanised_gdf.to_crs(hex_gdf.crs)\n",
    "# Urbanised hexagons: spatial join\n",
    "urban_hex_gdf = gpd.sjoin(hex_gdf, urbanised_gdf, how='inner', predicate='intersects').drop(columns=['index_right'])\n",
    "urban_hex_set = set(urban_hex_gdf['hexagon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e83dc695-034b-4765-88ce-009ce4b2cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_long = hex_df.stack().rename('hexagon')\n",
    "motive_long = motive_df.stack().rename('motive')\n",
    "expf_long = expf_df.stack().rename('tripexpfactor')\n",
    "long_df = pd.concat([hex_long, motive_long, expf_long], axis=1).reset_index()\n",
    "long_df = long_df[(long_df['hexagon'] != 'transit') & (long_df['motive'] != 'transit') & (long_df['tripexpfactor'] != 'transit')]\n",
    "long_df['hexagon'] = long_df['hexagon'].astype(str)\n",
    "long_df['motive'] = long_df['motive'].astype(int)\n",
    "long_df['tripexpfactor'] = pd.to_numeric(long_df['tripexpfactor'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84bf42d2-6eaf-40a1-8587-8539b57790b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating entropy in urbanised area only\n",
    "def entropy_weighted(counts):\n",
    "    p = np.array(counts, dtype=float)\n",
    "    total = p.sum()\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    p = p / total\n",
    "    p = p[p > 0]\n",
    "    return -np.sum(p * np.log2(p))\n",
    "\n",
    "motive_codes = sorted(long_df['motive'].unique())\n",
    "entropy_results = []\n",
    "for h, group in long_df.groupby('hexagon'):\n",
    "    motive_weights = group.groupby('motive')['tripexpfactor'].sum()\n",
    "    motive_weights = motive_weights.reindex(motive_codes, fill_value=0)\n",
    "    ent = entropy_weighted(motive_weights.values)\n",
    "    entropy_results.append({'hexagon': h, 'motive_entropy': ent})\n",
    "entropy_df = pd.DataFrame(entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe933b0-f23b-4620-99fd-856ded27a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging with urban hexes for plotting\n",
    "urban_hex_gdf['hexagon'] = urban_hex_gdf['hexagon'].astype(str)\n",
    "hex_entropy_map = urban_hex_gdf.merge(entropy_df, on=\"hexagon\", how=\"left\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1260d287-cebb-4ff3-ad85-670e0131a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting \n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "\n",
    "urbanised_gdf.plot(ax=ax, facecolor='lightgray', edgecolor='gray', linewidth=1, zorder=0)\n",
    "hex_entropy_map.plot(\n",
    "    column='motive_entropy',\n",
    "    cmap='hot',\n",
    "    legend=True,\n",
    "    legend_kwds={'shrink': 0.5},\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.1,\n",
    "    ax=ax,\n",
    "    zorder=1\n",
    ")\n",
    "\n",
    "hex_gdf.plot(ax=ax, facecolor='gainsboro', linewidth=1, zorder=0)\n",
    "\n",
    "plt.title(\"Expansion-Weighted Motive Entropy per Hexagon (Urbanised Areas Only)\", fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir,\"hexagon_motive_entropy_weighted_URBANISED.png\"), dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad9f670c-9de5-4f05-8afd-782cee2d77e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    11427.000000\n",
      "mean         0.509073\n",
      "std          0.589494\n",
      "min         -0.000000\n",
      "25%         -0.000000\n",
      "50%          0.257723\n",
      "75%          0.947145\n",
      "max          2.729837\n",
      "Name: motive_entropy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "summary_stats = entropy_df['motive_entropy'].describe()\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2c7bdc2-4ca6-4e32-9bbd-e10ca599d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of quarter-hour time labels\n",
    "quarter_labels = [f\"{h:02d}:{m:02d}\" for h in range(24) for m in [0, 15, 30, 45]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab05bfdc-8007-487c-aa4b-4694bd66c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean entropy per period (across urbanised hexes)\n",
    "mean_entropy_list = []\n",
    "for i in range(96):\n",
    "    hex_col = hex_df.iloc[:, i]\n",
    "    motive_col = motive_df.iloc[:, i]\n",
    "    expf_col = expf_df.iloc[:, i]\n",
    "    long_df = pd.DataFrame({\n",
    "        'hexagon': hex_col,\n",
    "        'motive': motive_col,\n",
    "        'tripexpfactor': expf_col\n",
    "    })\n",
    "    long_df = long_df[\n",
    "        (long_df['hexagon'] != 'transit') &\n",
    "        (long_df['motive'] != 'transit') &\n",
    "        (long_df['tripexpfactor'] != 'transit')\n",
    "    ]\n",
    "    long_df['hexagon'] = long_df['hexagon'].astype(str)\n",
    "    long_df['motive'] = pd.to_numeric(long_df['motive'], errors='coerce')\n",
    "    long_df['tripexpfactor'] = pd.to_numeric(long_df['tripexpfactor'], errors='coerce')\n",
    "    long_df = long_df.dropna(subset=['motive', 'tripexpfactor'])\n",
    "    long_df = long_df[long_df['hexagon'].isin(urban_hex_set)]\n",
    "    entropy_vals = []\n",
    "    motive_codes = sorted(long_df['motive'].unique())\n",
    "    for hexagon, group in long_df.groupby('hexagon'):\n",
    "        motive_weights = group.groupby('motive')['tripexpfactor'].sum()\n",
    "        motive_weights = motive_weights.reindex(motive_codes, fill_value=0)\n",
    "        entropy_vals.append(entropy_weighted(motive_weights.values))\n",
    "    # Take the mean for this period (skip empty slices)\n",
    "    if entropy_vals:\n",
    "        mean_entropy_list.append(np.mean(entropy_vals))\n",
    "    else:\n",
    "        mean_entropy_list.append(np.nan)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(quarter_labels, mean_entropy_list, marker='o', color='crimson')\n",
    "plt.xticks(range(0, 96, 4), [quarter_labels[i] for i in range(0, 96, 4)], rotation=45, ha='right')\n",
    "plt.xlabel(\"Quarter-hour interval\")\n",
    "plt.ylabel(\"Mean Motive Entropy\\n(per Urbanised Hexagon)\")\n",
    "plt.title(\"Temporal Profile of Mean Motive Entropy across Urbanised Area (15-Minute Resolution)\")\n",
    "plt.grid(True, alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir,\"urbanised_mean_motive_entropy_quarter_hour.png\"), dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a54c4d1-a241-4b1a-8d69-f508d12f69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== LISA AND PEAK-WINDOW ENTROPY ==========\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "peak_windows = {\n",
    "    '06:00–08:00': list(range(24, 32)),\n",
    "    '12:00–14:00': list(range(48, 56)),\n",
    "    '17:00–19:00': list(range(68, 76)),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa4c9614-b2cc-4954-8de8-5be1f3df635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse this from earlier, define if not already:\n",
    "def clean_long_df(long_df, urban_hex_set, drop_motives=None):\n",
    "    mask = (\n",
    "        (long_df['hexagon'] != 'transit') &\n",
    "        (long_df['motive'] != 'transit') &\n",
    "        (long_df['tripexpfactor'] != 'transit')\n",
    "    )\n",
    "    dfc = long_df.loc[mask].copy()\n",
    "    dfc['hexagon'] = dfc['hexagon'].astype(str)\n",
    "    dfc['motive'] = pd.to_numeric(dfc['motive'], errors='coerce')\n",
    "    dfc['tripexpfactor'] = pd.to_numeric(dfc['tripexpfactor'], errors='coerce')\n",
    "    dfc = dfc.dropna(subset=['motive', 'tripexpfactor'])\n",
    "    dfc = dfc[dfc['hexagon'].isin(urban_hex_set)]\n",
    "    if drop_motives is not None:\n",
    "        dfc = dfc[~dfc['motive'].isin(drop_motives)]\n",
    "    return dfc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "518d43c4-389c-456c-b0bb-a53cd8e16b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal.weights import Queen\n",
    "from esda.moran import Moran, Moran_Local\n",
    "\n",
    "# Custom colormap and cluster labels\n",
    "from matplotlib.colors import ListedColormap\n",
    "lisa_colormap = ListedColormap([\n",
    "    '#000000','#ff0000','#0000ff','#ffff00','#00ff00'\n",
    "])\n",
    "cluster_labels = ['Non-significant', 'High-High', 'Low-Low', 'Low-High', 'High-Low']\n",
    "\n",
    "entropy_map_results = {}\n",
    "\n",
    "for label, idxs in peak_windows.items():\n",
    "    # Get the relevant columns for each time window\n",
    "    hex_win = hex_df.iloc[:, idxs]\n",
    "    motive_win = motive_df.iloc[:, idxs]\n",
    "    expf_win = expf_df.iloc[:, idxs]\n",
    "    # Stack into long format\n",
    "    hex_long = hex_win.stack().rename('hexagon')\n",
    "    motive_long = motive_win.stack().rename('motive')\n",
    "    expf_long = expf_win.stack().rename('tripexpfactor')\n",
    "    long_df_p = pd.concat([hex_long, motive_long, expf_long], axis=1).reset_index(drop=True)\n",
    "    clean_df = clean_long_df(long_df_p, urban_hex_set)\n",
    "\n",
    "    motive_codes = sorted(clean_df['motive'].unique())\n",
    "    entropy_list = []\n",
    "    for h, group in clean_df.groupby('hexagon'):\n",
    "        motive_weights = group.groupby('motive')['tripexpfactor'].sum()\n",
    "        motive_weights = motive_weights.reindex(motive_codes, fill_value=0)\n",
    "        ent = entropy_weighted(motive_weights.values)\n",
    "        entropy_list.append({'hexagon': h, 'motive_entropy': ent})\n",
    "    entropy_df_p = pd.DataFrame(entropy_list)\n",
    "\n",
    "    # Merge with spatial info\n",
    "    map_gdf = urban_hex_gdf.merge(entropy_df_p, on='hexagon', how='left').fillna({'motive_entropy': 0})\n",
    "    entropy_map_results[label] = map_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e97f5d1-2dc9-4cc2-8f79-c323236433b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/libpysal/weights/contiguity.py:347: UserWarning: The weights matrix is not fully connected: \n",
      " There are 282 disconnected components.\n",
      " There are 51 islands with ids: 618, 974, 1016, 1513, 2091, 2297, 3127, 4152, 4639, 5031, 5101, 5484, 5535, 5746, 6367, 6369, 6500, 7176, 7879, 8229, 8401, 9263, 9964, 10437, 11057, 11277, 11669, 12368, 13403, 13828, 14623, 14884, 15413, 17010, 17055, 17188, 17208, 17378, 17681, 19128, 19418, 19722, 19828, 19924, 20314, 21028, 21101, 21281, 21822, 22217, 22234.\n",
      "  W.__init__(self, neighbors, ids=ids, **kw)\n"
     ]
    }
   ],
   "source": [
    "w = Queen.from_dataframe(urban_hex_gdf, use_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e51bdbcd-ef41-444e-9e17-60720cdb6d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WARNING: ', 618, ' is an island (no neighbors)')\n",
      "('WARNING: ', 974, ' is an island (no neighbors)')\n",
      "('WARNING: ', 1016, ' is an island (no neighbors)')\n",
      "('WARNING: ', 1513, ' is an island (no neighbors)')\n",
      "('WARNING: ', 2091, ' is an island (no neighbors)')\n",
      "('WARNING: ', 2297, ' is an island (no neighbors)')\n",
      "('WARNING: ', 3127, ' is an island (no neighbors)')\n",
      "('WARNING: ', 4152, ' is an island (no neighbors)')\n",
      "('WARNING: ', 4639, ' is an island (no neighbors)')\n",
      "('WARNING: ', 5031, ' is an island (no neighbors)')\n",
      "('WARNING: ', 5101, ' is an island (no neighbors)')\n",
      "('WARNING: ', 5484, ' is an island (no neighbors)')\n",
      "('WARNING: ', 5535, ' is an island (no neighbors)')\n",
      "('WARNING: ', 5746, ' is an island (no neighbors)')\n",
      "('WARNING: ', 6367, ' is an island (no neighbors)')\n",
      "('WARNING: ', 6369, ' is an island (no neighbors)')\n",
      "('WARNING: ', 6500, ' is an island (no neighbors)')\n",
      "('WARNING: ', 7176, ' is an island (no neighbors)')\n",
      "('WARNING: ', 7879, ' is an island (no neighbors)')\n",
      "('WARNING: ', 8229, ' is an island (no neighbors)')\n",
      "('WARNING: ', 8401, ' is an island (no neighbors)')\n",
      "('WARNING: ', 9263, ' is an island (no neighbors)')\n",
      "('WARNING: ', 9964, ' is an island (no neighbors)')\n",
      "('WARNING: ', 10437, ' is an island (no neighbors)')\n",
      "('WARNING: ', 11057, ' is an island (no neighbors)')\n",
      "('WARNING: ', 11277, ' is an island (no neighbors)')\n",
      "('WARNING: ', 11669, ' is an island (no neighbors)')\n",
      "('WARNING: ', 12368, ' is an island (no neighbors)')\n",
      "('WARNING: ', 13403, ' is an island (no neighbors)')\n",
      "('WARNING: ', 13828, ' is an island (no neighbors)')\n",
      "('WARNING: ', 14623, ' is an island (no neighbors)')\n",
      "('WARNING: ', 14884, ' is an island (no neighbors)')\n",
      "('WARNING: ', 15413, ' is an island (no neighbors)')\n",
      "('WARNING: ', 17010, ' is an island (no neighbors)')\n",
      "('WARNING: ', 17055, ' is an island (no neighbors)')\n",
      "('WARNING: ', 17188, ' is an island (no neighbors)')\n",
      "('WARNING: ', 17208, ' is an island (no neighbors)')\n",
      "('WARNING: ', 17378, ' is an island (no neighbors)')\n",
      "('WARNING: ', 17681, ' is an island (no neighbors)')\n",
      "('WARNING: ', 19128, ' is an island (no neighbors)')\n",
      "('WARNING: ', 19418, ' is an island (no neighbors)')\n",
      "('WARNING: ', 19722, ' is an island (no neighbors)')\n",
      "('WARNING: ', 19828, ' is an island (no neighbors)')\n",
      "('WARNING: ', 19924, ' is an island (no neighbors)')\n",
      "('WARNING: ', 20314, ' is an island (no neighbors)')\n",
      "('WARNING: ', 21028, ' is an island (no neighbors)')\n",
      "('WARNING: ', 21101, ' is an island (no neighbors)')\n",
      "('WARNING: ', 21281, ' is an island (no neighbors)')\n",
      "('WARNING: ', 21822, ' is an island (no neighbors)')\n",
      "('WARNING: ', 22217, ' is an island (no neighbors)')\n",
      "('WARNING: ', 22234, ' is an island (no neighbors)')\n",
      "06:00–08:00: Moran's I = 0.341, p = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/esda/moran.py:1084: RuntimeWarning: invalid value encountered in divide\n",
      "  self.z_sim = (self.Is - self.EI_sim) / self.seI_sim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:00–14:00: Moran's I = 0.433, p = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/esda/moran.py:1084: RuntimeWarning: invalid value encountered in divide\n",
      "  self.z_sim = (self.Is - self.EI_sim) / self.seI_sim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:00–19:00: Moran's I = 0.408, p = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/esda/moran.py:1084: RuntimeWarning: invalid value encountered in divide\n",
      "  self.z_sim = (self.Is - self.EI_sim) / self.seI_sim\n"
     ]
    }
   ],
   "source": [
    "for label, gdf in entropy_map_results.items():\n",
    "    y = gdf['motive_entropy'].values\n",
    "    moran = Moran(y, w)\n",
    "    print(f\"{label}: Moran's I = {moran.I:.3f}, p = {moran.p_sim:.3f}\")\n",
    "    lisa = Moran_Local(y, w)\n",
    "    gdf['lisa_q'] = lisa.q\n",
    "    gdf['lisa_p'] = lisa.p_sim\n",
    "    sig = gdf['lisa_p'] < 0.05\n",
    "    cluster = gdf['lisa_q']\n",
    "    gdf['lisa_type'] = np.where(sig, cluster, 0)\n",
    "    gdf['lisa_type'] = pd.to_numeric(gdf['lisa_type'], downcast='integer', errors='coerce').fillna(0).astype(int)\n",
    "    # Save back into the dict for possible export\n",
    "    entropy_map_results[label] = gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0386e762-00fd-4d23-a74b-6a52144fccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, gdf in entropy_map_results.items():\n",
    "    fig, ax = plt.subplots(figsize=(13,12))\n",
    "    urbanised_gdf.plot(ax=ax, facecolor='lightgray', edgecolor='gray', linewidth=0.3, zorder=0)\n",
    "    hex_gdf.boundary.plot(ax=ax, facecolor='gainsboro', color='white', linewidth=0.1, zorder=2)\n",
    "    gdf.plot(column='lisa_type', cmap=lisa_colormap, ax=ax, legend=False,\n",
    "             edgecolor='k', linewidth=0.1, vmin=0, vmax=4, zorder=3)\n",
    "    for i, l in enumerate(cluster_labels):\n",
    "        ax.scatter([], [], color=lisa_colormap.colors[i], label=l)\n",
    "    ax.legend(frameon=True, fontsize=13, title=\"LISA Cluster\", loc=\"lower left\")\n",
    "    ax.set_title(f\"LISA Clusters Motive Entropy ({label}), Urbanised Hexagons\", fontsize=17)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    fname = f\"lisa_clusters_motive_entropy_urbanised_{label.replace(':','').replace('–','-')}.png\"\n",
    "    plt.savefig(os.path.join(output_dir, fname), dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfbc4ddc-dd15-43dd-ac88-f3fab4bdb080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build counts per window in a single table\n",
    "summary = pd.DataFrame()\n",
    "for label, gdf in entropy_map_results.items():\n",
    "    counts = gdf['lisa_type'].value_counts().reindex(range(5), fill_value=0)\n",
    "    summary = pd.concat([summary, counts.rename(label)], axis=1)\n",
    "summary = summary.T\n",
    "summary.columns = cluster_labels\n",
    "summary_path = os.path.join(output_dir, \"MOTIVE_Lisa_Cluster_Summary.csv\")\n",
    "summary.to_csv(summary_path, index=True)\n",
    "# Exclude Non-significant column for the plot\n",
    "summary_no_ns = summary.drop(columns=['Non-significant'])\n",
    "bar_colors_no_ns = lisa_colormap.colors[1:]  # HH, LL, LH, HL\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "bottom = np.zeros(len(summary_no_ns))\n",
    "for col, color in zip(summary_no_ns.columns, bar_colors_no_ns):\n",
    "    ax.bar(summary_no_ns.index, summary_no_ns[col].values, label=col, bottom=bottom, color=color)\n",
    "    bottom += summary_no_ns[col].values\n",
    "\n",
    "ax.set_ylabel('Number of hexagons')\n",
    "ax.set_title('LISA Cluster Types by Time Period (Excluding Non-significant)\\n(Urbanised Area only)')\n",
    "ax.legend(title='LISA Cluster Type')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plot_path = os.path.join(output_dir, 'MOTIVE_Lisa_Cluster_Types_by_Time_Period_Urbanised_NoNonSig.png')\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c028d738-854b-4dd2-8fbf-4d232e93434e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Non-significant  High-High  Low-Low  Low-High  High-Low\n",
      "06:00–08:00            19275       1493     1004       133       378\n",
      "12:00–14:00            13162       2125      872      5837       287\n",
      "17:00–19:00            19289       1678      879       126       311\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "492cf191-f2b6-47a6-b4d5-5ee689e70436",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_gdf.to_csv(os.path.join(output_dir,\"motive_entropy.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed3e6f59-edc5-44e3-8f07-d425534353b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy of Economic groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54ed3cfa-2ce4-4553-bdb7-b49a827cb238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def econ_group(code):\n",
    "    code = int(code)\n",
    "    if code == 1: return 'High (A)'\n",
    "    elif code in [2,3]: return 'Upper middle (B1/B2)'\n",
    "    elif code in [4,5]: return 'Lower middle (C1/C2)'\n",
    "    elif code == 6: return 'Low (D/E)'\n",
    "    return 'Unknown'\n",
    "\n",
    "econ_groups = ['High (A)', 'Upper middle (B1/B2)', 'Lower middle (C1/C2)', 'Low (D/E)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6851edf1-02e1-481c-b841-42d78d2a10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_path = os.path.join(output_dir, \"cleandbf.csv\")\n",
    "cleaned_df = pd.read_csv(cleaned_path, dtype=str, low_memory=False)\n",
    "cleaned_df['econ_group'] = cleaned_df['CRITERIOBR'].apply(econ_group)\n",
    "person_exp_df = cleaned_df.drop_duplicates(subset='ID_PESS')[['ID_PESS','FE_PESS','econ_group']]\n",
    "person_exp_df['FE_PESS'] = person_exp_df['FE_PESS'].astype(float)\n",
    "person_exp = person_exp_df.set_index('ID_PESS').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2b0c703-d984-4123-8b93-edd91ea41d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    11147.000000\n",
      "mean         0.521250\n",
      "std          0.526707\n",
      "min         -0.000000\n",
      "25%         -0.000000\n",
      "50%          0.467868\n",
      "75%          0.970417\n",
      "max          1.979707\n",
      "Name: econ_entropy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "person_hex_path = os.path.join(output_dir, \"OD_ADULTS_Timeindex_Motive_location_tripexpansionfactors.csv\")\n",
    "person_hex_df = pd.read_csv(person_hex_path, dtype=str, low_memory=False)\n",
    "\n",
    "# Whole day: all intervals as strings\n",
    "all_cols = list(map(str, range(96)))\n",
    "wholeday_long = person_hex_df.melt(id_vars=['ID_PESS'],\n",
    "                                   value_vars=all_cols,\n",
    "                                   var_name='interval',\n",
    "                                   value_name='hexagon')  # wide→long\n",
    "wholeday_long = wholeday_long[wholeday_long['hexagon'] != 'transit']\n",
    "wholeday_long['hexagon'] = wholeday_long['hexagon'].astype(str)\n",
    "wholeday_long['FE_PESS'] = wholeday_long['ID_PESS'].map(lambda x: person_exp.get(x, {}).get('FE_PESS', np.nan))\n",
    "wholeday_long['econ_group'] = wholeday_long['ID_PESS'].map(lambda x: person_exp.get(x, {}).get('econ_group', 'Unknown'))\n",
    "wholeday_long = wholeday_long.dropna(subset=['FE_PESS'])\n",
    "# Urbanised only\n",
    "wholeday_long = wholeday_long[wholeday_long['hexagon'].isin(urban_hex_set)]\n",
    "\n",
    "# Entropy per hex\n",
    "entropy_results = []\n",
    "for hx, grp in wholeday_long.groupby('hexagon'):\n",
    "    s = grp.groupby('econ_group')['FE_PESS'].sum().reindex(econ_groups, fill_value=0)\n",
    "    entropy_results.append({'hexagon': hx, 'econ_entropy': entropy_weighted(s.values)})\n",
    "econ_entropy_df = pd.DataFrame(entropy_results)\n",
    "\n",
    "# Joining to geo and plotting\n",
    "econ_entropy_map = urban_hex_gdf.merge(econ_entropy_df, on=\"hexagon\", how=\"left\").fillna(0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "urbanised_gdf.plot(ax=ax, facecolor='lightgray', edgecolor='gray', linewidth=1, zorder=0)\n",
    "econ_entropy_map.plot(column='econ_entropy', cmap='hot', legend=True,\n",
    "                      legend_kwds={'shrink': 0.5}, edgecolor=\"black\", linewidth=0.1, ax=ax, zorder=1)\n",
    "hex_gdf.plot(ax=ax, facecolor='gainsboro', linewidth=1, zorder=0)\n",
    "plt.title(\"Expansion-Weighted Economic Group Entropy per Hexagon (Whole Day, Urbanised Areas Only)\", fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir,\"hexagon_econ_entropy_weighted_URBANISED.png\"),\n",
    "            dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "plt.close()\n",
    "\n",
    "print(econ_entropy_df['econ_entropy'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "169c8019-b9fa-4e7b-9632-f7cee869a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter_labels = [f\"{h:02d}:{m:02d}\" for h in range(24) for m in [0, 15, 30, 45]]\n",
    "\n",
    "mean_econ_entropy = []\n",
    "for i in range(96):\n",
    "    win_long = person_hex_df.melt(id_vars=['ID_PESS'], value_vars=[str(i)],\n",
    "                                  var_name='interval', value_name='hexagon')\n",
    "    win_long = win_long[win_long['hexagon'] != 'transit']\n",
    "    win_long['hexagon'] = win_long['hexagon'].astype(str)\n",
    "    win_long['FE_PESS'] = win_long['ID_PESS'].map(lambda x: person_exp.get(x, {}).get('FE_PESS', np.nan))\n",
    "    win_long['econ_group'] = win_long['ID_PESS'].map(lambda x: person_exp.get(x, {}).get('econ_group', 'Unknown'))\n",
    "    win_long = win_long.dropna(subset=['FE_PESS'])\n",
    "    win_long = win_long[win_long['hexagon'].isin(urban_hex_set)]\n",
    "    ent_vals = []\n",
    "    for h, g in win_long.groupby('hexagon'):\n",
    "        weights = g.groupby('econ_group')['FE_PESS'].sum().reindex(econ_groups, fill_value=0)\n",
    "        ent_vals.append(entropy_weighted(weights.values))\n",
    "    mean_econ_entropy.append(np.mean(ent_vals) if ent_vals else np.nan)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(quarter_labels, mean_econ_entropy, marker='o', color='navy')\n",
    "plt.xticks(range(0, 96, 4), [quarter_labels[i] for i in range(0, 96, 4)], rotation=45, ha='right')\n",
    "plt.xlabel(\"Quarter-hour interval\"); plt.ylabel(\"Mean Economic Group Entropy\\n(per Urbanised Hexagon)\")\n",
    "plt.title(\"Temporal Profile of Mean Economic Group Entropy across Urbanised Area (15-Minute Resolution)\")\n",
    "plt.grid(True, alpha=0.4); plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"urbanised_mean_econgroup_entropy_quarter_hour.png\"),\n",
    "            dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd12353a-1d87-4c91-9cb3-5a550bdd364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_windows_str = {k: list(map(str, v)) for k, v in peak_windows.items()}\n",
    "\n",
    "econ_entropy_maps = {}\n",
    "\n",
    "# Computing entropy per peak window\n",
    "for window_label, cols in peak_windows_str.items():\n",
    "    win_long = person_hex_df.melt(id_vars=['ID_PESS'], value_vars=cols,\n",
    "                                  var_name='interval', value_name='hexagon')\n",
    "    win_long = win_long[win_long['hexagon'] != 'transit']\n",
    "    win_long['hexagon'] = win_long['hexagon'].astype(str)\n",
    "    win_long['FE_PESS'] = win_long['ID_PESS'].map(lambda x: person_exp.get(x, {}).get('FE_PESS', np.nan))\n",
    "    win_long['econ_group'] = win_long['ID_PESS'].map(lambda x: person_exp.get(x, {}).get('econ_group', 'Unknown'))\n",
    "    win_long = win_long.dropna(subset=['FE_PESS'])\n",
    "    # Urban filter\n",
    "    win_long = win_long[win_long['hexagon'].isin(urban_hex_set)]\n",
    "    \n",
    "    # Entropy per hex\n",
    "    ent_rows = []\n",
    "    for hx, grp in win_long.groupby('hexagon'):\n",
    "        s = grp.groupby('econ_group')['FE_PESS'].sum().reindex(econ_groups, fill_value=0)\n",
    "        ent_rows.append({'hexagon': hx, 'econ_entropy': entropy_weighted(s.values)})\n",
    "    ent_df = pd.DataFrame(ent_rows)\n",
    "\n",
    "    # Join to geometry; store for LISA\n",
    "    gdf_win = urban_hex_gdf.merge(ent_df, on='hexagon', how='left').fillna({'econ_entropy': 0})\n",
    "    econ_entropy_maps[window_label] = gdf_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "970355b3-eebf-4232-997c-321aabc98eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:00–08:00: Moran's I = 0.388, p = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/esda/moran.py:1084: RuntimeWarning: invalid value encountered in divide\n",
      "  self.z_sim = (self.Is - self.EI_sim) / self.seI_sim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:00–14:00: Moran's I = 0.433, p = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/esda/moran.py:1084: RuntimeWarning: invalid value encountered in divide\n",
      "  self.z_sim = (self.Is - self.EI_sim) / self.seI_sim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:00–19:00: Moran's I = 0.396, p = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/esda/moran.py:1084: RuntimeWarning: invalid value encountered in divide\n",
      "  self.z_sim = (self.Is - self.EI_sim) / self.seI_sim\n"
     ]
    }
   ],
   "source": [
    "# LISA per peak window using the same spatial weights w\n",
    "from esda.moran import Moran, Moran_Local\n",
    "\n",
    "for label, gdf_win in econ_entropy_maps.items():\n",
    "    y = gdf_win['econ_entropy'].values\n",
    "    moran = Moran(y, w)\n",
    "    print(f\"{label}: Moran's I = {moran.I:.3f}, p = {moran.p_sim:.3f}\")\n",
    "    lisa = Moran_Local(y, w)\n",
    "    sig = lisa.p_sim < 0.05\n",
    "    gdf_win['lisa_type'] = np.where(sig, lisa.q, 0).astype(int)\n",
    "\n",
    "    # Plot LISA clusters (exclude separate non-sig plot as requested)\n",
    "    fig, ax = plt.subplots(figsize=(13,12))\n",
    "    urbanised_gdf.plot(ax=ax, facecolor='lightgray', edgecolor='gray', linewidth=0.3, zorder=0)\n",
    "    hex_gdf.boundary.plot(ax=ax, facecolor='gainsboro', color='white', linewidth=0.1, zorder=2)\n",
    "    gdf_win.plot(column='lisa_type', cmap=lisa_colormap, ax=ax, legend=False,\n",
    "                 edgecolor='k', linewidth=0.1, vmin=0, vmax=4, zorder=3)\n",
    "    for i, l in enumerate(cluster_labels):\n",
    "        ax.scatter([], [], color=lisa_colormap.colors[i], label=l)\n",
    "    ax.legend(frameon=True, fontsize=13, title=\"LISA Cluster\", loc=\"lower left\")\n",
    "    ax.set_title(f\"LISA Clusters of Economic Entropy ({label})\\nUrbanised Hexagons, p < 0.05\", fontsize=17)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"lisa_clusters_econ_entropy_urbanised_{label.replace(':','').replace('–','-')}.png\"),\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11e0cb26-3203-46c1-94dd-ed0683789d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary counts including Non-significant\n",
    "econ_summary = pd.DataFrame()\n",
    "for label, gdf_e in econ_entropy_maps.items():\n",
    "    counts = gdf_e['lisa_type'].value_counts().reindex(range(5), fill_value=0)\n",
    "    econ_summary = pd.concat([econ_summary, counts.rename(label)], axis=1)\n",
    "econ_summary = econ_summary.T\n",
    "econ_summary.columns = cluster_labels\n",
    "econ_summary.to_csv(os.path.join(output_dir, \"ECON_Lisa_Cluster_Summary.csv\"))\n",
    "\n",
    "# Excluding Non-significant for the bar plot\n",
    "econ_summary_no_ns = econ_summary.drop(columns=['Non-significant'])\n",
    "bar_colors_no_ns = lisa_colormap.colors[1:]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "bottom = np.zeros(len(econ_summary_no_ns))\n",
    "for col, color in zip(econ_summary_no_ns.columns, bar_colors_no_ns):\n",
    "    ax.bar(econ_summary_no_ns.index, econ_summary_no_ns[col].values, label=col, bottom=bottom, color=color)\n",
    "    bottom += econ_summary_no_ns[col].values\n",
    "\n",
    "ax.set_ylabel('Number of hexagons')\n",
    "ax.set_title('LISA Cluster Types by Time Period (Excluding Non-significant)\\nEconomic Group Entropy (Urbanised Area only)')\n",
    "ax.legend(title='LISA Cluster Type')\n",
    "plt.xticks(rotation=0); plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'ECONGROUP_Lisa_Cluster_Types_by_Time_Period_Urbanised_NoNonSig.png'),\n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd726678-7a43-422b-ada4-f91cf4f741c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_win.to_csv(os.path.join(output_dir,\"econ_entropy.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e882027-7992-4be7-88bd-6a2ef8e0848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Overlap Summary: 06:00–08:00 ===\n",
      "econ_lisa        0     1    2     3    4\n",
      "motive_lisa                             \n",
      "0            16802   608  523  6819  209\n",
      "1              289  1135   97     0    2\n",
      "2              439   244  357     0    0\n",
      "3                4     0    0   278    1\n",
      "4              276     9    2     9   82\n",
      "Exact code match: 18654/28185 (66.2%)\n",
      "Cohen's kappa: 0.218\n",
      "HH matches: 1135\n",
      "\n",
      "=== Overlap Summary: 12:00–14:00 ===\n",
      "econ_lisa        0     1    2     3    4\n",
      "motive_lisa                             \n",
      "0            12050   341  367  3265  205\n",
      "1              347  1687  125     0    0\n",
      "2              316   148  426     0    0\n",
      "3             6640     0    6  1958   15\n",
      "4              188     1    0    12   88\n",
      "Exact code match: 16209/28185 (57.5%)\n",
      "Cohen's kappa: 0.209\n",
      "HH matches: 1687\n",
      "\n",
      "=== Overlap Summary: 17:00–19:00 ===\n",
      "econ_lisa        0     1    2     3    4\n",
      "motive_lisa                             \n",
      "0            20857   468  515  2942  241\n",
      "1              294  1270  122     0    0\n",
      "2              340   201  351     9    0\n",
      "3               16     0    0   246    2\n",
      "4              223     6    1     0   81\n",
      "Exact code match: 22805/28185 (80.9%)\n",
      "Cohen's kappa: 0.382\n",
      "HH matches: 1270\n"
     ]
    }
   ],
   "source": [
    "# Matching High–High LISA\n",
    "\n",
    "municipal_gdf = gpd.read_file(\"ucl-mres-thesis/Municipal boundaries-ShapeFiles/Municipios_2023.shp\")\n",
    "\n",
    "if hex_gdf.crs != municipal_gdf.crs:\n",
    "    municipal_gdf = municipal_gdf.to_crs(hex_gdf.crs)\n",
    "    \n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "#  Making lightweight dicts with only the needed columns and consistent names\n",
    "motive_lisa = {}\n",
    "econ_lisa = {}\n",
    "\n",
    "for period, gdf in entropy_map_results.items():  # motive\n",
    "    cols = [c for c in ['hexagon','geometry','lisa_type'] if c in gdf.columns]\n",
    "    motive_lisa[period] = gdf[cols].copy()\n",
    "\n",
    "for period, gdf in econ_entropy_maps.items():  # econ\n",
    "    cols = [c for c in ['hexagon','geometry','lisa_type'] if c in gdf.columns]\n",
    "    econ_lisa[period] = gdf[cols].copy()\n",
    "\n",
    "# Ensuring period keys match between the two analyses \n",
    "common_periods = [p for p in motive_lisa.keys() if p in econ_lisa.keys()]\n",
    "if not common_periods:\n",
    "    raise RuntimeError(\"No overlapping periods between motive and econ LISA results.\")\n",
    "\n",
    "# Overlapping stats and HH-only matches per period\n",
    "overlap_stats = {}\n",
    "hh_matches_gdfs = {} \n",
    "\n",
    "for period in common_periods:\n",
    "    g_m = motive_lisa[period].rename(columns={'lisa_type':'motive_lisa'})\n",
    "    g_e = econ_lisa[period].rename(columns={'lisa_type':'econ_lisa'})\n",
    "\n",
    "    \n",
    "    merged = g_m.merge(g_e[['hexagon','econ_lisa']], on='hexagon', how='inner')\n",
    "    cross = pd.crosstab(merged['motive_lisa'], merged['econ_lisa'])\n",
    "    cross = cross.reindex(index=range(5), columns=range(5), fill_value=0)\n",
    "\n",
    "    # Agreement metrics \n",
    "    agree = (merged['motive_lisa'] == merged['econ_lisa']).sum()\n",
    "    total = len(merged)\n",
    "    percent = 100 * agree / total if total > 0 else np.nan\n",
    "    kappa = cohen_kappa_score(merged['motive_lisa'], merged['econ_lisa'])\n",
    "\n",
    "    # HH-only matches\n",
    "    hh_match = merged[(merged['motive_lisa'] == 1) & (merged['econ_lisa'] == 1)].copy()\n",
    "    hh_matches_gdfs[period] = hh_match\n",
    "\n",
    "    overlap_stats[period] = {\n",
    "        'crosstab': cross,\n",
    "        'agree': agree,\n",
    "        'total': total,\n",
    "        'percent': percent,\n",
    "        'kappa': kappa,\n",
    "        'hh_count': len(hh_match)\n",
    "    }\n",
    "\n",
    "# Printing summary to console and export CSVs\n",
    "for period, stats in overlap_stats.items():\n",
    "    print(f\"\\n=== Overlap Summary: {period} ===\")\n",
    "    print(stats['crosstab'])\n",
    "    print(f\"Exact code match: {stats['agree']}/{stats['total']} ({stats['percent']:.1f}%)\")\n",
    "    print(f\"Cohen's kappa: {stats['kappa']:.3f}\")\n",
    "    print(f\"HH matches: {stats['hh_count']}\")\n",
    "\n",
    "    safe = period.replace(':','').replace('–','-')\n",
    "    stats['crosstab'].to_csv(os.path.join(output_dir, f\"Overlap_Crosstab_{safe}.csv\"))\n",
    "    pd.DataFrame([{\n",
    "        'period': period,\n",
    "        'agree': stats['agree'],\n",
    "        'total': stats['total'],\n",
    "        'percent': stats['percent'],\n",
    "        'kappa': stats['kappa'],\n",
    "        'hh_count': stats['hh_count']\n",
    "    }]).to_csv(os.path.join(output_dir, f\"Overlap_Summary_{safe}.csv\"), index=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "\n",
    "def plot_hh_matches(period, color='mediumvioletred'):\n",
    "    g_m = motive_lisa[period].rename(columns={'lisa_type': 'motive_lisa'})\n",
    "    g_e = econ_lisa[period].rename(columns={'lisa_type': 'econ_lisa'})\n",
    "    merged = g_m.merge(g_e[['hexagon', 'econ_lisa']], on='hexagon', how='inner')\n",
    "    gdf_hh = merged[(merged['motive_lisa'] == 1) & (merged['econ_lisa'] == 1)].copy()\n",
    "\n",
    "    if gdf_hh.empty:\n",
    "        print(f\"No matching High–High clusters for {period}.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(13, 12))\n",
    "\n",
    "    urbanised_gdf.plot(ax=ax, facecolor='lightgray', edgecolor='gray', linewidth=0.3, zorder=0)\n",
    "    municipal_gdf.boundary.plot(ax=ax, color='black', linewidth=0.7, zorder=1)\n",
    "    gdf_hh.plot(ax=ax, color='mediumvioletred', edgecolor='white', linewidth=0.12, zorder=2)\n",
    "\n",
    "    # Legend\n",
    "    handles = [Patch(facecolor=color, edgecolor='white', label=\"Matching HH\", alpha=0.85)]\n",
    "    ax.legend(handles=handles, loc='upper right', fontsize=15, frameon=True, title='Cluster Type')\n",
    "\n",
    "    ax.set_title(f\"Matching High–High LISA Clusters (Motive & Econ)\\n{period}\", fontsize=17)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Set limits with a buffer so nothing is cropped\n",
    "    minx, miny, maxx, maxy = urbanised_gdf.total_bounds\n",
    "    buffer = 0.1 * max(maxx - minx, maxy - miny)\n",
    "    ax.set_xlim(minx - buffer, maxx + buffer)\n",
    "    ax.set_ylim(miny - buffer, maxy + buffer)\n",
    "    plt.tight_layout()\n",
    "    safe = period.replace(':', '').replace('–', '-')\n",
    "    plt.savefig(os.path.join(output_dir, f\"Matching_HH_LISA_{safe}_doubleboundary.png\"),\n",
    "                dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "\n",
    "for period in ['06:00–08:00','12:00–14:00','17:00–19:00']:\n",
    "    if period in motive_lisa:\n",
    "        plot_hh_matches(period)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
